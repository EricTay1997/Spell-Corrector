{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = open('dictionary.txt').read().split('\\n')\n",
    "# dictionary.txt is a txt file of all valid words taken from the link on Piazza\n",
    "# https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('unigram_freq.csv', index_col = False)\n",
    "# unigram_freq.csv is a csv file from Kaggle, containing english words and word frequency\n",
    "# Data is derived from the Google Web Trillion Word Corpus.\n",
    "# https://www.kaggle.com/rtatman/english-word-frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['word'].isin(all_words)] # Clean kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = {}\n",
    "for i in range(len(df)):\n",
    "    word_counter[df.iloc[i,0]] = df.iloc[i,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in all_words:\n",
    "    if word not in word_counter:\n",
    "        word_counter[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3086225277"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter[\"I\"] = word_counter[\"i\"]\n",
    "word_counter.pop(\"i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_corrector(word_list):\n",
    "    return [correct(word) for word in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrects word if it's alphanumeric\n",
    "# Else, do nothing\n",
    "# Capitalizes it accordingly\n",
    "def correct(word):\n",
    "    if not word.isalnum():\n",
    "        return word\n",
    "    if word == \"I\":\n",
    "        return \"I\"\n",
    "    corrected_word = best_candidate(word.lower())\n",
    "    if word.isupper():\n",
    "        return corrected_word.upper()\n",
    "    if word[0].isupper():\n",
    "        return corrected_word[0].upper() + corrected_word[1:]\n",
    "    return corrected_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns best candidate for a given word\n",
    "# Prioritizes lower Levenshtein distance, and then word frequency\n",
    "# If there are no words with Levenshtein distance â‰¤ 2 in word_counter, return the word itself\n",
    "def best_candidate(word):\n",
    "    return (best_candidate_from_list([word]) or best_candidate_from_list(distance1(word)) \n",
    "            or best_candidate_from_list(distance2(word)) or [word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns best candidate from a list of words\n",
    "# Weighted by word frequency\n",
    "def best_candidate_from_list(words):\n",
    "    count = -1\n",
    "    candidate = None\n",
    "    for w in words:\n",
    "        if w in word_counter and word_counter[w] > count:\n",
    "            count = word_counter[w]\n",
    "            candidate = w\n",
    "    return candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of words of one Levenshtein distance from word\n",
    "def distance1(word):\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    ret = set()\n",
    "    for i in range(len(word)):\n",
    "        ret.add(word[:i] + word[i+1:]) #Deletion\n",
    "        for letter in letters:\n",
    "            ret.add(word[:i] + letter + word[i:]) #Insertion\n",
    "            ret.add(word[:i] + letter + word[i+1:]) #Substitution\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of words of two Levenshtein distance from word\n",
    "def distance2(word): \n",
    "    ret = set()\n",
    "    for distance1_word in distance1(word):\n",
    "        ret.update(distance1(distance1_word))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHAPTER',\n",
       " ' ',\n",
       " 'a',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'The',\n",
       " 'family',\n",
       " 'of',\n",
       " 'Basswood',\n",
       " 'had',\n",
       " 'long',\n",
       " 'been',\n",
       " 'settled',\n",
       " 'a',\n",
       " 'Sussex.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [\"CHAPOTER\", \" \", \"1\", \"\\n\", \"\\n\", \"\\n\", \"The\", \"family\", \"of\", \"Dashwood\", \"had\", \"long\", \"been\", \"settled\", \"i\", \"Sussex.\"]\n",
    "spell_corrector(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
